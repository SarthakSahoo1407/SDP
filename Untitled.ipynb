{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6f7c61d-6493-40cc-bdfb-4f26f3b28c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba22c6f2-7029-4868-8696-4daf217dd80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1293adfd-c734-4e73-872c-ba342a027894",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('thyroid_cancer_risk_data.csv')\n",
    "data.drop('Patient_ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd090a8b-673d-41f4-96cb-21a839492a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Family_History</th>\n",
       "      <th>Radiation_Exposure</th>\n",
       "      <th>Iodine_Deficiency</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>TSH_Level</th>\n",
       "      <th>T3_Level</th>\n",
       "      <th>T4_Level</th>\n",
       "      <th>Nodule_Size</th>\n",
       "      <th>Thyroid_Cancer_Risk</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>Male</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>9.37</td>\n",
       "      <td>1.67</td>\n",
       "      <td>6.16</td>\n",
       "      <td>1.08</td>\n",
       "      <td>Low</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.73</td>\n",
       "      <td>10.54</td>\n",
       "      <td>4.05</td>\n",
       "      <td>Low</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>Male</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>6.26</td>\n",
       "      <td>2.59</td>\n",
       "      <td>10.57</td>\n",
       "      <td>4.61</td>\n",
       "      <td>Low</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>Female</td>\n",
       "      <td>India</td>\n",
       "      <td>Asian</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.62</td>\n",
       "      <td>11.04</td>\n",
       "      <td>2.46</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>Germany</td>\n",
       "      <td>African</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>9.10</td>\n",
       "      <td>2.11</td>\n",
       "      <td>10.71</td>\n",
       "      <td>2.11</td>\n",
       "      <td>High</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Country  Ethnicity Family_History Radiation_Exposure  \\\n",
       "0   66    Male   Russia  Caucasian             No                Yes   \n",
       "1   29    Male  Germany   Hispanic             No                Yes   \n",
       "2   86    Male  Nigeria  Caucasian             No                 No   \n",
       "3   75  Female    India      Asian             No                 No   \n",
       "4   35  Female  Germany    African            Yes                Yes   \n",
       "\n",
       "  Iodine_Deficiency Smoking Obesity Diabetes  TSH_Level  T3_Level  T4_Level  \\\n",
       "0                No      No      No       No       9.37      1.67      6.16   \n",
       "1                No      No      No       No       1.83      1.73     10.54   \n",
       "2                No      No      No       No       6.26      2.59     10.57   \n",
       "3                No      No      No       No       4.10      2.62     11.04   \n",
       "4                No      No      No       No       9.10      2.11     10.71   \n",
       "\n",
       "   Nodule_Size Thyroid_Cancer_Risk Diagnosis  \n",
       "0         1.08                 Low    Benign  \n",
       "1         4.05                 Low    Benign  \n",
       "2         4.61                 Low    Benign  \n",
       "3         2.46              Medium    Benign  \n",
       "4         2.11                High    Benign  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf56503d-b310-4248-ad75-d2ba24121229",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = ['Gender', 'Family_History', 'Radiation_Exposure', \n",
    "               'Iodine_Deficiency', 'Smoking', 'Obesity', 'Diabetes']\n",
    "data[binary_cols] = data[binary_cols].replace({'Male': 1, 'Female': 0, 'Yes': 1, 'No': 0})\n",
    "\n",
    "risk_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "data['Thyroid_Cancer_Risk'] = data['Thyroid_Cancer_Risk'].map(risk_mapping)\n",
    "\n",
    "X = data.drop('Diagnosis', axis=1)\n",
    "y = data['Diagnosis'].map({'Benign': 0, 'Malignant': 1})  # Explicit target mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec860a8a-d3b4-4c2b-bcb2-5c4e8b10621d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Family_History</th>\n",
       "      <th>Radiation_Exposure</th>\n",
       "      <th>Iodine_Deficiency</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>TSH_Level</th>\n",
       "      <th>T3_Level</th>\n",
       "      <th>T4_Level</th>\n",
       "      <th>Nodule_Size</th>\n",
       "      <th>Thyroid_Cancer_Risk</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212686</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>India</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11.92</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212687</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.77</td>\n",
       "      <td>3.25</td>\n",
       "      <td>7.30</td>\n",
       "      <td>4.46</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212688</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.72</td>\n",
       "      <td>2.44</td>\n",
       "      <td>8.71</td>\n",
       "      <td>2.36</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212689</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.62</td>\n",
       "      <td>2.53</td>\n",
       "      <td>9.62</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212690</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>2.73</td>\n",
       "      <td>10.59</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender  Country       Ethnicity  Family_History  \\\n",
       "212686   58       0    India           Asian               0   \n",
       "212687   89       1    Japan  Middle Eastern               0   \n",
       "212688   72       0  Nigeria        Hispanic               0   \n",
       "212689   85       0   Brazil  Middle Eastern               0   \n",
       "212690   46       0    Japan  Middle Eastern               0   \n",
       "\n",
       "        Radiation_Exposure  Iodine_Deficiency  Smoking  Obesity  Diabetes  \\\n",
       "212686                   0                  0        0        1         0   \n",
       "212687                   0                  0        0        1         0   \n",
       "212688                   0                  0        0        0         1   \n",
       "212689                   0                  0        0        0         1   \n",
       "212690                   0                  0        1        0         0   \n",
       "\n",
       "        TSH_Level  T3_Level  T4_Level  Nodule_Size  Thyroid_Cancer_Risk  \\\n",
       "212686       2.00      0.64     11.92         1.48                    0   \n",
       "212687       9.77      3.25      7.30         4.46                    1   \n",
       "212688       7.72      2.44      8.71         2.36                    1   \n",
       "212689       5.62      2.53      9.62         1.54                    1   \n",
       "212690       5.60      2.73     10.59         2.53                    0   \n",
       "\n",
       "        Diagnosis  \n",
       "212686     Benign  \n",
       "212687     Benign  \n",
       "212688     Benign  \n",
       "212689     Benign  \n",
       "212690  Malignant  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6ac3f92-a9f8-4dd8-85c8-e94021928b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y.isnull().sum())  # Check how many NaNs are in y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ff0b68e-212f-4e76-b461-c05751381f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af1f4270-3cdb-490e-83d5-464df6b419f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Country', 'Ethnicity']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afb98b11-fb71-403f-bcd2-f38e97ed61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e3c356f-78fd-46fb-b86c-98ca39bc4bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_processed, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4c427c6-0149-4dca-a89f-59f4c616209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb67b021-a963-425e-9df4-0ec39c012e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_params(model, model_name):\n",
    "    \"\"\"Save model to pickle and parameters to JSON\"\"\"\n",
    "    # Save model\n",
    "    with open(f'{model_name}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(model.best_estimator_, f)\n",
    "    \n",
    "    # Save parameters\n",
    "    params = {\n",
    "        'best_params': model.best_params_,\n",
    "        'best_score': float(model.best_score_)  # Convert numpy float to Python float\n",
    "    }\n",
    "    with open(f'{model_name}_params.json', 'w') as f:\n",
    "        json.dump(params, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6108437e-b8be-48d2-ba65-b6360bde0aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dt_params = {'max_depth': [3, 5, 7], 'min_samples_split': [2, 5]}\n",
    "dt = GridSearchCV(DecisionTreeClassifier(), dt_params, \n",
    "                cv=5, scoring='recall', verbose=3, n_jobs=-1)\n",
    "dt.fit(X_train_smote, y_train_smote)\n",
    "save_model_and_params(dt, 'decision_tree')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43f4bd0b-69a6-466a-a3c4-da3160df0bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_params = {'n_estimators': [100, 200], 'max_depth': [5, 7]}\n",
    "rf = GridSearchCV(RandomForestClassifier(), rf_params,\n",
    "                cv=5, scoring='recall', verbose=3, n_jobs=-1)\n",
    "rf.fit(X_train_smote, y_train_smote)\n",
    "save_model_and_params(rf, 'random_forest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9fa0f78-36f3-4d1c-8a57-a4fd83a8d53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[CV 3/5] END ..max_depth=3, min_samples_split=2;, score=0.652 total time=   2.1s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_split=2;, score=0.748 total time=   2.4s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_split=5;, score=0.743 total time=   2.2s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_split=5;, score=0.623 total time=   3.0s\n",
      "[CV 2/2] END ..max_depth=5, min_samples_split=2;, score=0.723 total time=   1.5s\n",
      "[CV 2/2] END .....max_depth=5, n_estimators=200;, score=0.779 total time=  43.0s\n",
      "[CV 2/2] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.945 total time= 5.2min\n",
      "[CV 1/5] END ..max_depth=3, min_samples_split=5;, score=0.449 total time=   2.4s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_split=5;, score=0.438 total time=   2.6s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_split=2;, score=0.820 total time=   2.9s\n",
      "[CV 1/2] END ..max_depth=3, min_samples_split=2;, score=0.529 total time=   1.3s\n",
      "[CV 1/2] END ..max_depth=7, min_samples_split=5;, score=0.572 total time=   1.4s\n",
      "[CV 1/2] END .....max_depth=7, n_estimators=200;, score=0.615 total time=  56.7s\n",
      "[CV 2/2] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.873 total time= 3.3min\n",
      "[CV 2/2] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.995 total time= 3.0min\n",
      "[CV 2/5] END ..max_depth=3, min_samples_split=2;, score=0.548 total time=   2.1s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_split=2;, score=0.723 total time=   2.4s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_split=5;, score=0.748 total time=   2.2s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_split=5;, score=0.818 total time=   3.0s\n",
      "[CV 2/2] END ..max_depth=3, min_samples_split=2;, score=0.648 total time=   1.0s\n",
      "[CV 1/2] END ..max_depth=7, min_samples_split=2;, score=0.572 total time=   1.6s\n",
      "[CV 2/2] END .....max_depth=5, n_estimators=100;, score=0.759 total time=  25.9s\n",
      "[CV 1/2] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.567 total time= 2.4min\n",
      "[CV 2/2] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.990 total time= 1.6min\n",
      "[CV 2/2] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.995 total time= 2.4min\n",
      "[CV 5/5] END ..max_depth=3, min_samples_split=2;, score=0.644 total time=   2.1s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_split=2;, score=0.594 total time=   2.7s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_split=2;, score=0.623 total time=   3.1s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_split=5;, score=0.800 total time=   2.3s\n",
      "[CV 1/2] END ..max_depth=5, min_samples_split=5;, score=0.567 total time=   1.7s\n",
      "[CV 2/2] END .....max_depth=7, n_estimators=200;, score=0.907 total time=  50.8s\n",
      "[CV 2/2] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=0.912 total time= 2.7min\n",
      "[CV 1/2] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.432 total time= 4.1min\n",
      "[CV 2/5] END ..max_depth=3, min_samples_split=5;, score=0.548 total time=   1.9s\n",
      "[CV 4/5] END ..max_depth=3, min_samples_split=5;, score=0.649 total time=   1.8s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_split=5;, score=0.723 total time=   2.1s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_split=2;, score=0.800 total time=   3.0s\n",
      "[CV 1/2] END ..max_depth=3, min_samples_split=5;, score=0.529 total time=   1.3s\n",
      "[CV 2/2] END ..max_depth=7, min_samples_split=5;, score=0.800 total time=   1.2s\n",
      "[CV 2/2] END .....max_depth=7, n_estimators=100;, score=0.908 total time=  30.7s\n",
      "[CV 1/2] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.623 total time= 6.9min\n",
      "[CV 3/5] END ..max_depth=3, min_samples_split=5;, score=0.652 total time=   1.8s\n",
      "[CV 5/5] END ..max_depth=3, min_samples_split=5;, score=0.644 total time=   1.7s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_split=5;, score=0.594 total time=   2.2s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_split=5;, score=0.440 total time=   3.3s\n",
      "[CV 1/2] END ..max_depth=5, min_samples_split=2;, score=0.567 total time=   1.9s\n",
      "[CV 1/2] END .....max_depth=5, n_estimators=200;, score=0.574 total time=  51.0s\n",
      "[CV 1/2] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=0.607 total time= 3.7min\n",
      "[CV 1/2] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.442 total time= 3.2min\n",
      "[CV 4/5] END ..max_depth=3, min_samples_split=2;, score=0.649 total time=   2.1s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_split=2;, score=0.438 total time=   2.7s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_split=2;, score=0.818 total time=   2.9s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_split=5;, score=0.820 total time=   2.3s\n",
      "[CV 2/2] END ..max_depth=5, min_samples_split=5;, score=0.723 total time=   1.2s\n",
      "[CV 1/2] END .....max_depth=5, n_estimators=100;, score=0.571 total time=  30.5s\n",
      "[CV 1/2] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.592 total time= 4.5min\n",
      "[CV 2/2] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.995 total time= 3.5min\n",
      "[CV 1/5] END ..max_depth=3, min_samples_split=2;, score=0.449 total time=   2.3s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_split=2;, score=0.743 total time=   2.3s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_split=2;, score=0.440 total time=   3.4s\n",
      "[CV 2/2] END ..max_depth=3, min_samples_split=5;, score=0.648 total time=   1.0s\n",
      "[CV 2/2] END ..max_depth=7, min_samples_split=2;, score=0.800 total time=   1.3s\n",
      "[CV 1/2] END .....max_depth=7, n_estimators=100;, score=0.615 total time=  37.1s\n",
      "[CV 2/2] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.816 total time= 1.7min\n",
      "[CV 1/2] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.545 total time= 2.2min\n",
      "[CV 1/2] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.405 total time= 4.7min\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_params = {'n_estimators': [100, 200], \n",
    "             'learning_rate': [0.01, 0.1], \n",
    "             'max_depth': [3, 5]}\n",
    "gb = GridSearchCV(GradientBoostingClassifier(), gb_params,\n",
    "                cv=5, scoring='recall', verbose=3, n_jobs=-1)\n",
    "gb.fit(X_train_smote, y_train_smote)\n",
    "save_model_and_params(gb, 'gradient_boosting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d125fcaf-41e9-41a1-9c1b-edef74f9a74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[CV 3/5] END ..max_depth=3, min_samples_split=2;, score=0.652 total time=   2.1s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_split=2;, score=0.748 total time=   2.4s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_split=5;, score=0.743 total time=   2.2s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_split=5;, score=0.623 total time=   3.0s\n",
      "[CV 2/2] END ..max_depth=5, min_samples_split=2;, score=0.723 total time=   1.5s\n",
      "[CV 2/2] END .....max_depth=5, n_estimators=200;, score=0.779 total time=  43.0s\n",
      "[CV 2/2] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.945 total time= 5.2min\n",
      "[CV 1/5] END ..max_depth=3, min_samples_split=5;, score=0.449 total time=   2.4s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_split=5;, score=0.438 total time=   2.6s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_split=2;, score=0.820 total time=   2.9s\n",
      "[CV 1/2] END ..max_depth=3, min_samples_split=2;, score=0.529 total time=   1.3s\n",
      "[CV 1/2] END ..max_depth=7, min_samples_split=5;, score=0.572 total time=   1.4s\n",
      "[CV 1/2] END .....max_depth=7, n_estimators=200;, score=0.615 total time=  56.7s\n",
      "[CV 2/2] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.873 total time= 3.3min\n",
      "[CV 2/2] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.995 total time= 3.0min\n",
      "[CV 2/5] END ..max_depth=3, min_samples_split=2;, score=0.548 total time=   2.1s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_split=2;, score=0.723 total time=   2.4s\n",
      "[CV 4/5] END ..max_depth=5, min_samples_split=5;, score=0.748 total time=   2.2s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_split=5;, score=0.818 total time=   3.0s\n",
      "[CV 2/2] END ..max_depth=3, min_samples_split=2;, score=0.648 total time=   1.0s\n",
      "[CV 1/2] END ..max_depth=7, min_samples_split=2;, score=0.572 total time=   1.6s\n",
      "[CV 2/2] END .....max_depth=5, n_estimators=100;, score=0.759 total time=  25.9s\n",
      "[CV 1/2] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.567 total time= 2.4min\n",
      "[CV 2/2] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.990 total time= 1.6min\n",
      "[CV 2/2] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.995 total time= 2.4min\n",
      "[CV 5/5] END ..max_depth=3, min_samples_split=2;, score=0.644 total time=   2.1s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_split=2;, score=0.594 total time=   2.7s\n",
      "[CV 2/5] END ..max_depth=7, min_samples_split=2;, score=0.623 total time=   3.1s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_split=5;, score=0.800 total time=   2.3s\n",
      "[CV 1/2] END ..max_depth=5, min_samples_split=5;, score=0.567 total time=   1.7s\n",
      "[CV 2/2] END .....max_depth=7, n_estimators=200;, score=0.907 total time=  50.8s\n",
      "[CV 2/2] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=0.912 total time= 2.7min\n",
      "[CV 1/2] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.432 total time= 4.1min\n",
      "[CV 2/5] END ..max_depth=3, min_samples_split=5;, score=0.548 total time=   1.9s\n",
      "[CV 4/5] END ..max_depth=3, min_samples_split=5;, score=0.649 total time=   1.8s\n",
      "[CV 3/5] END ..max_depth=5, min_samples_split=5;, score=0.723 total time=   2.1s\n",
      "[CV 5/5] END ..max_depth=7, min_samples_split=2;, score=0.800 total time=   3.0s\n",
      "[CV 1/2] END ..max_depth=3, min_samples_split=5;, score=0.529 total time=   1.3s\n",
      "[CV 2/2] END ..max_depth=7, min_samples_split=5;, score=0.800 total time=   1.2s\n",
      "[CV 2/2] END .....max_depth=7, n_estimators=100;, score=0.908 total time=  30.7s\n",
      "[CV 1/2] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.623 total time= 6.9min\n",
      "[CV 3/5] END ..max_depth=3, min_samples_split=5;, score=0.652 total time=   1.8s\n",
      "[CV 5/5] END ..max_depth=3, min_samples_split=5;, score=0.644 total time=   1.7s\n",
      "[CV 2/5] END ..max_depth=5, min_samples_split=5;, score=0.594 total time=   2.2s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_split=5;, score=0.440 total time=   3.3s\n",
      "[CV 1/2] END ..max_depth=5, min_samples_split=2;, score=0.567 total time=   1.9s\n",
      "[CV 1/2] END .....max_depth=5, n_estimators=200;, score=0.574 total time=  51.0s\n",
      "[CV 1/2] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=0.607 total time= 3.7min\n",
      "[CV 1/2] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.442 total time= 3.2min\n",
      "[CV 4/5] END ..max_depth=3, min_samples_split=2;, score=0.649 total time=   2.1s\n",
      "[CV 1/5] END ..max_depth=5, min_samples_split=2;, score=0.438 total time=   2.7s\n",
      "[CV 3/5] END ..max_depth=7, min_samples_split=2;, score=0.818 total time=   2.9s\n",
      "[CV 4/5] END ..max_depth=7, min_samples_split=5;, score=0.820 total time=   2.3s\n",
      "[CV 2/2] END ..max_depth=5, min_samples_split=5;, score=0.723 total time=   1.2s\n",
      "[CV 1/2] END .....max_depth=5, n_estimators=100;, score=0.571 total time=  30.5s\n",
      "[CV 1/2] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.592 total time= 4.5min\n",
      "[CV 2/2] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.995 total time= 3.5min\n",
      "[CV 1/5] END ..max_depth=3, min_samples_split=2;, score=0.449 total time=   2.3s\n",
      "[CV 5/5] END ..max_depth=5, min_samples_split=2;, score=0.743 total time=   2.3s\n",
      "[CV 1/5] END ..max_depth=7, min_samples_split=2;, score=0.440 total time=   3.4s\n",
      "[CV 2/2] END ..max_depth=3, min_samples_split=5;, score=0.648 total time=   1.0s\n",
      "[CV 2/2] END ..max_depth=7, min_samples_split=2;, score=0.800 total time=   1.3s\n",
      "[CV 1/2] END .....max_depth=7, n_estimators=100;, score=0.615 total time=  37.1s\n",
      "[CV 2/2] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.816 total time= 1.7min\n",
      "[CV 1/2] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.545 total time= 2.2min\n",
      "[CV 1/2] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.405 total time= 4.7min\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_params = {'n_estimators': [100, 200], \n",
    "             'learning_rate': [0.01, 0.1], \n",
    "             'max_depth': [3, 5]}\n",
    "gb = GridSearchCV(GradientBoostingClassifier(), gb_params,\n",
    "                cv=5, scoring='recall', verbose=3, n_jobs=-1)\n",
    "gb.fit(X_train_smote, y_train_smote)\n",
    "save_model_and_params(gb, 'gradient_boosting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95e9c1de-b5f1-492f-a5ea-4e0c1b893402",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <FBD6AEF9-AFAB-39D7-B881-755157DA0497> /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file)\"]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# XGBoost\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m      4\u001b[0m xgb_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m      5\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m      6\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m]}\n\u001b[1;32m      7\u001b[0m xgb \u001b[38;5;241m=\u001b[39m GridSearchCV(XGBClassifier(use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      8\u001b[0m                  xgb_params, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective, dask\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     Booster,\n\u001b[1;32m     10\u001b[0m     DataIter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     build_info,\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/tracker.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, make_jcargs\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/core.py:269\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m _LIB \u001b[38;5;241m=\u001b[39m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m        return value from API calls\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/core.py:222\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[1;32m    221\u001b[0m         libname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(lib_paths[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) could not be loaded.\u001b[39m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124mLikely causes:\u001b[39m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124m  * OpenMP runtime is not installed\u001b[39m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m \u001b[38;5;124m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[1;32m    233\u001b[0m \n\u001b[1;32m    234\u001b[0m \u001b[38;5;124mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    237\u001b[0m     _register_log_callback(lib)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(ver: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n",
      "\u001b[0;31mXGBoostError\u001b[0m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <FBD6AEF9-AFAB-39D7-B881-755157DA0497> /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file)\"]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_params = {'n_estimators': [100, 200],\n",
    "              'learning_rate': [0.01, 0.1],\n",
    "              'max_depth': [3, 5]}\n",
    "xgb = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "                 xgb_params, cv=5, scoring='recall', verbose=3, n_jobs=-1)\n",
    "xgb.fit(X_train_smote, y_train_smote)\n",
    "save_model_and_params(xgb, 'xgboost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1e9c9ee-8c18-4739-abf6-b57accc74b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'AUC-ROC': roc_auc_score(y_test, y_proba)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf8fba5e-85c3-416b-ba5b-7df80cd21e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Comparison:\n",
      "                   Accuracy  Precision    Recall  F1-Score   AUC-ROC\n",
      "Decision Tree      0.828454   0.704025  0.453499  0.551651  0.696474\n",
      "Random Forest      0.828595   0.704731  0.453431  0.551817  0.697837\n",
      "Gradient Boosting  0.828595   0.704731  0.453431  0.551817  0.700439\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Decision Tree': pickle.load(open('decision_tree_model.pkl', 'rb')),\n",
    "    'Random Forest': pickle.load(open('random_forest_model.pkl', 'rb')),\n",
    "    'Gradient Boosting': pickle.load(open('gradient_boosting_model.pkl', 'rb')),\n",
    "    # 'XGBoost': pickle.load(open('xgboost_model.pkl', 'rb'))\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    results[name] = evaluate_model(model, X_test_processed, y_test)\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "51e8d175-496f-41a1-bd79-7b7e7cd20e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Prediction:\n",
      "{'Decision Tree': {'prediction': 'Benign', 'confidence': 0.058}, 'Random Forest': {'prediction': 'Benign', 'confidence': 0.263}, 'Gradient Boosting': {'prediction': 'Benign', 'confidence': 0.241}}\n"
     ]
    }
   ],
   "source": [
    "def predict_example(sample_data):\n",
    "    \"\"\"Example prediction function\"\"\"\n",
    "    processed_data = preprocessor.transform(sample_data)\n",
    "    predictions = {}\n",
    "    for name, model in models.items():\n",
    "        proba = model.predict_proba(processed_data)[0][1]\n",
    "        predictions[name] = {\n",
    "            'prediction': 'Malignant' if proba >= 0.5 else 'Benign',\n",
    "            'confidence': round(proba, 3)\n",
    "        }\n",
    "    return predictions\n",
    "\n",
    "# Test prediction\n",
    "sample = X_test.sample(1, random_state=42)\n",
    "print(\"\\nSample Prediction:\")\n",
    "print(predict_example(sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be3326b-e346-47ab-bd01-2eb1c56f1220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
